{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Day 10 -CNN- MNIST handwritten image classification using VGG16- Transfer Learning</h1>"
      ],
      "metadata": {
        "id": "bN6o4NyF5_oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Essential modules"
      ],
      "metadata": {
        "id": "VB1QV3oU6PVg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4e5IU_upwXW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical , plot_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import models,layers\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the MNIST Data"
      ],
      "metadata": {
        "id": "EuAwmzHSu65u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=keras.datasets.mnist.load_data()\n"
      ],
      "metadata": {
        "id": "sLTGPj68qkMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fdb2d05-556d-4fda-ba21-ee63bf357a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmwPmFjhqwEc",
        "outputId": "966c8dee-71f2-4a9f-82a5-a7e561b0a33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "[5 0 4 ... 5 6 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the data to make it compatible  with the VGG16 model\n"
      ],
      "metadata": {
        "id": "aacvG0XQrLXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.dstack([x_train]*3)\n",
        "x_test=np.dstack([x_test]*3)\n",
        "x_train.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maKH-I5frSch",
        "outputId": "c26bbd46-512a-49e1-dc55-40a032610725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 84), (10000, 28, 84))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape images as per the tensor format required by tensorflow\n"
      ],
      "metadata": {
        "id": "kafUDKQesjNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(-1,28,28,3)\n",
        "x_test=x_test.reshape(-1,28,28,3)\n",
        "x_train.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS0ujiKAr78k",
        "outputId": "8571e461-a488-4de3-bdac-50e06db83f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 3), (10000, 28, 28, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the images into 48*48 as required for VGG16"
      ],
      "metadata": {
        "id": "ZGhA5GkwsXba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "\n",
        "x_train = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in x_train])\n",
        "x_test = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in x_test])\n",
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWrSq2UUsLDn",
        "outputId": "535339c2-f31c-4252-c5ce-f619c74ed66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 48, 48, 3), (10000, 48, 48, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the Data for the VGG16 model"
      ],
      "metadata": {
        "id": "Ms-5GpXG6aVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "x=x_train\n",
        "y=[]\n",
        "y=y_train\n",
        "\n",
        "y=to_categorical(y)\n",
        "x=np.array(x)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=5)"
      ],
      "metadata": {
        "id": "dJZyCJxN2wet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defing the Model using Transfer learning"
      ],
      "metadata": {
        "id": "-GIpDNe9tKnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "model_vgg16=VGG16(weights='imagenet')\n",
        "\n"
      ],
      "metadata": {
        "id": "Kdkmp8YQspQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5337d9fc-bccf-404e-b3e3-487c39fe40e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the input layer to the model"
      ],
      "metadata": {
        "id": "BVT3WqVLvPu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer=layers.Input(shape=(48,48,3))\n",
        "model_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "WwlCq34pvVs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de2c9644-7e2d-4ece-f155-705957202d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the output layers"
      ],
      "metadata": {
        "id": "69wTk3czv-es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer=model_vgg16.output\n",
        "flatten=layers.Flatten()(last_layer)\n",
        "dense1=layers.Dense(100,activation='relu')(flatten)\n",
        "dense1=layers.Dense(100,activation='relu')(flatten)\n",
        "dense1=layers.Dense(100,activation='relu')(flatten)\n",
        "output_layer=layers.Dense(10,activation='softmax')(flatten)\n",
        "\n",
        "model=models.Model(inputs=input_layer,outputs=output_layer)\n"
      ],
      "metadata": {
        "id": "1POwpVSnv94N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are making all the layers intrainable except the last layer."
      ],
      "metadata": {
        "id": "sTcZL4nC0hF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:-1]:\n",
        "    layer.trainable=False\n"
      ],
      "metadata": {
        "id": "lOG-AMYbtjId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compiling the model\n"
      ],
      "metadata": {
        "id": "4Kdvl6At0sDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compilation completed.\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOLOtONq0iLy",
        "outputId": "51beda78-1c88-4816-c56e-18fba91dff83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compilation completed.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14719818 (56.15 MB)\n",
            "Trainable params: 5130 (20.04 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model fitting"
      ],
      "metadata": {
        "id": "zhWDU2XF5eKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train,epochs=20,batch_size=128,verbose=True,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "id": "6HTXr0DX0uzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "EQ-OlVLy5mMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n"
      ],
      "metadata": {
        "id": "Dw5xT3Wu5lnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The loss is \",loss,\"And the accuracy is \",accuracy)"
      ],
      "metadata": {
        "id": "bKpm2t0K5o7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}